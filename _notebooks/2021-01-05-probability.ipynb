{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit ('bsoid_v2': conda)",
   "metadata": {
    "interpreter": {
     "hash": "70658d0dc983cc69301b6a3d852019c9464e36a3224cbdef5e94f06265ffc19d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Probability for Computational Biologists\n",
    "> A comprehensive outline of prudent concepts in probability.\n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [jupyter]\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Introduction\n",
    "\n",
    "This will be a comprehensive outline of topics in probability, including random variables, distributions, and rules of probability. My hope is that this will serve as a picture of (almost) everything you need may need to know regarding probability.\n",
    "\n",
    "Topics such as statistical and deep learning leverage these concepts as assumed knowledge. It is therefore vital to have at least working knowledge of what is to come."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Counting\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Multiplication Rule\n",
    "\n",
    "Given an experiment with many potential outcomes, we can simply multiply the number of outcomes at each step for the overall number of possible outcomes.\n",
    "\n",
    "$n_{total} = \\prod_i n_i$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Sampling\n",
    "\n",
    "Sampling $k$ items from a population of size $n$ results in the number of possibilities as follows:\n",
    "\n",
    "- Replacement (place each of the $k$ samples back into the population after choosing!)\n",
    "    - Order-Preserving (we count each unique order in which we select the $k$ samples)\n",
    "        - $n^k$\n",
    "    - Order Doesn't Matter (we only care about the class membership of the $k samples)\n",
    "        - $ {n+k-1}\\choose{k} $      \n",
    "\n",
    "- No Replacement\n",
    "    - Order-Preserving\n",
    "        - $\\frac{n!}{(n-k)!}$\n",
    "        - A *permutations* problem.\n",
    "    - Order Doesn't Matter\n",
    "        - $n\\choose k$ = $\\frac{n!}{k!(n-k)!}$\n",
    "        - A *combinations* problem; use the binomial coefficient"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Na√Øve Probability\n",
    "\n",
    "- If all outcomes in a given event space are equally likely, $P_{naive}(X=x_i) = \\frac{\\text{outcomes favorable to } x_i}{\\text{number of outcomes}}$\n",
    "\n",
    "- This is intuitive. The probability of heads given a strictly fair coin (i.e., $X\\sim Bernoulli(p=.50)$) over two trials is $\\frac{1}{2}$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Conditional Probability"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Independence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Independent Events\n",
    "\n",
    "Two events $A,B$ are independent if the outcome of one event has no bearing on the other. In other words, knowing the outcome of $B$ gives no information about the potential outcome of $A$:\n",
    "\n",
    "- For independent events $A,B$,\n",
    "    - $P(A,B) = P(A)P(B)$\n",
    "    - $P(A|B) = P(A)$\n",
    "    - $P(B|A) = P(B)$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Conditional Independence\n",
    "\n",
    "Two events $A,B$ are *conditionally* independent given another event outcome $C$ if: $$P(A,B|C) = P(A|C)P(B|C)$$ That is, we can tease apart the probability of a given event if they share a relevant background variable.\n",
    "\n",
    "As an example, take the problem of three genetic mutations, $i,j$ and $k$. Let $i$ and $j$ be tightly correlated in a dataset and assume the probability distributions of each event is known. At first glance, we might think we could never model the two mutations independently. We may even assume $i$ causes $j$ in some fashion, or vice versa.\n",
    "\n",
    "However, if we discovered that $k$ was a definitely a mutation appearing in an upstream promoter region impacting both sites corresponding to $i$ and $j$, we could then show conditional independence between $i$ and $j$ given the mutation $k$. Suddenly, our assumptions change and we may be more inclined to target $k$ as an event outcome worthy of attention."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Unions, Intersects, Complements\n",
    "\n",
    "Set theory can be useful in the realm of probabilty. At the end of the day, we use probabilistic models to try and understand real events. This is the case with both discrete and continuous outcomes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### De Morgan's Laws\n",
    "\n",
    "De Morgan's Laws offer versatility in logical reasoning, proofs, set theory, and other areas of intrigue. One thing to note is that generally, we frequently use $AND$ and $OR$ operators in probability. Note the following:\n",
    "\n",
    "- $\\lnot(A \\lor B)= \\lnot A \\land \\lnot B $\n",
    "- $\\lnot(A \\land B) = \\lnot A \\lor \\lnot B $"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Joint, Marginal, and Conditional Probability\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Joint Probability\n",
    "\n",
    "- $P(A,B)$\n",
    "    - Note, $P(A,B) = P(A)P(B|A)$\n",
    "    - We can tease apart the distributions by conditioning on the portion of the event space occupied by $B$ where $A$ also has a bearing.\n",
    "    \n",
    "    - Note also how $P(A,B)=P(B,A) = P(B)P(A|B)$. While consistency is important, this is just a matter of our choice of labels on the events."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Marginal (Unconditional / Prior) Probability\n",
    "- $P(A)$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Conditional Probability\n",
    "\n",
    "- $P(A|B) = \\frac{P(A,B)}{P(B)}$\n",
    "- *The Probability of A given B is equal to the Probability of A and B over the (prior) Probability of B*\n",
    "\n",
    "- Note: We can easily see how Bayes' Rule follows. Given that we can \"flip\" the order of the joint probability expression, what is the right side equivalent to?\n",
    "    - $P(A|B) = \\frac{P(A,B)}{P(B)} \\to P(A|B)P(B) = P(A,B) = P(B|A)P(A)$\n",
    "    - $\\implies P(A,B) = \\frac{P(B|A)P(A)}{P(B)}$, or Bayes' Rule!\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Conditional Probability *is* Probability\n",
    "\n",
    "- $P(A|B)$ is a probability function like any other for a fixed $B$. Any theorem applicable to probability is relevant for conditional probability."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Chain Rule for Probability\n",
    "\n",
    "- Note we can disentangle a joint probability by use of the \"chain\" rule, an extension of operations on two-event probabilities.\n",
    "- $P(A,B,C) = P(A|B,C)P(B,C) = P(A|B,C)P(B|C)P(C)$.\n",
    "- This is exaclty the same as calling the joint event space $B,C = D$ and writing $P(A,D) = P(A|D)P(D)$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Law of Total Probability\n",
    "\n",
    "For an event $A$ and disjoint sample partitions $B_1,...,B_n$, we can always marginalize out irrelevant event spaces.\n",
    "\n",
    "- $P(A) = P(A|B_1)P(B_1) + ... + P(A|B_n)P(P_n)$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Bayes' Rule\n",
    "\n",
    "Combining the definitions of conditional probility $P(A|B) = \\frac{P(A,B)}{P(B)}$ and joint probability $P(A,B) = P(A|B)P(B) = P(B|A)P(A)$, we can describe Bayes' Rule:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "For 3 events $A,B,C$, we can write $$P(A|B,C)  = \\frac{P(A,B,C)}{P(B,C)} = \\frac{P(B,C|A)P(A)}{P(B,C)}$$\n",
    "\n",
    "We can also use the chain rule to our liking:\n",
    "\n",
    "$$P(A|B,C) = \\frac{P(A,B,C)}{P(B,C)} = \\frac{P(A|B,C)P(B|C)P(C)}{P(B|C)P(C)} = P(A|B,C)$$\n",
    "\n",
    "Note that it may be useful to commute these terms depending on the circumstance."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Random Variables and their Distributions\n",
    "\n",
    "A random variable can take on a number of values according to a mathematical function. This may be thought of as the probability of a given outcome of an experiment in a global sense."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Probability Mass Functions (PMF) and Probability Distribution Functions (PDF)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Cumulative Distribution Functions (CDF)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Survival Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Independence of Random Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Expected Values and Indicators "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Expected Values and Linearity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Expected Values\n",
    "\n",
    "Mean, expectation, or first moment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Linearity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### $\\text{Distribution} \\implies \\text{Mean}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Conditional Expected Value"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Indicator Random Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Indicator RVs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Distribution of an Indicator RV "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Fundamental Bridge of an Indicator RV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Variance and Standard Deviation (w.r.t. Expectation)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Continuous Random Variables, Law of the Unconscious Statistician (LOTUS), and the Universaility of Uniform (UoU)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Continuous Random Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Probability of a CRV in a Given Interval"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### The Probability Density Function of a CRV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Expected Values of CRVs versus DRVs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "###  Law of the Unconscious Statistician (LOTUS)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### $g(RV_i) = RV_j$: The function of a random variable is itself a random variable.\n",
    "\n",
    "- I.e., one need only know the PMF/PDF of $X$ to find the PMF/PDF of $g(x)$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Universality of Uniform / Probability Integral Transform\n",
    "\n",
    "- Substitution of any $X_{cts}$ into its cumulative distribution function $F_X(x) = P(X\\leq x)$ yields $U(0,1)$.\n",
    "- Let $Y=F_X(X)$. Then, $F_Y(y) = P(Y \\leq y) = P(F_X(X) \\leq y) = P(X\\leq F^{-1}(y)) = F_X(F_X^{-1}(y)) = y$ for $Y\\sim U(0,1)$ and $X$ is some continous random variable with CDF $F_X$.\n",
    "\n",
    "    - I.e. $F_X(X_{cts}) = \\int_{-\\infty}^{x}f(t)dt = \\int_{-\\infty}^{x}P(X\\leq t)dt = X \\sim U(0,1)$.\n",
    "\n",
    "Now, in Python."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Moments and Moment-Generating Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Moments"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Moment-Generating Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Joint Probability Density Functions (PDFs) and Comulative Distribution Functions (CDFs)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Joint Distributions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Conditional Distributions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Bayes' Rule for Discrete RVs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Bayes' Rule for Continuous RVs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Marginal Distributions\n",
    "- Discrete Case: Marginal PMF from Joint PMF\n",
    "- Continous Case: Marginal PDF from Joint PDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Independence of Random Variables\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Multivariate LOTUS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#  Further Topics\n",
    "\n",
    "We will now take a look at topics that are more practical and/or obscure, such as relevant distributions and Markov Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Covariance and Transformations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Covariance and Correlation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Covariance and Independence"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Covariance and Variance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Properties of Covariance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Correlation: Location and Space-Invariant"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Transformations\n",
    "\n",
    "- Single Variable\n",
    "\n",
    "- Two Variables\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Convolutions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Convolution Integral"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Relevance to \"Convolutional\" Neural Networks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Poisson Processes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Law of Large Numbers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Central Limit Theorem"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Markov Chains\n",
    "\n",
    "### Markov Property\n",
    "\n",
    "### States\n",
    "\n",
    "### Transition Matrix\n",
    "\n",
    "### Chain Properties\n",
    "\n",
    "### Stationary DIstributions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Some Continuous Distribitions\n",
    "\n",
    "## Normal\n",
    "\n",
    "## Exponential\n",
    "\n",
    "## Gamma\n",
    "\n",
    "## Beta\n",
    "\n",
    "## Chi-Square"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Some Discrete Distribitions\n",
    "\n",
    "## Sampling: Varying Number of Trials and Replacement\n",
    "\n",
    "## Bernoulli\n",
    "\n",
    "## Binomial\n",
    "\n",
    "## Geometric\n",
    "\n",
    "## First-Success\n",
    "\n",
    "## Negative Binomial\n",
    "\n",
    "## Hypergeometric\n",
    "\n",
    "## Poisson"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Some Multivariate Distributions\n",
    "\n",
    "## Multinomial\n",
    "\n",
    "## Multivariate Uniform\n",
    "\n",
    "## Multivariate Normal\n",
    "\n",
    "## A Note on Mixture Models\n",
    "\n",
    "### EM and Mixture Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# In Case You Missed It: Special Cases of Distributions\n",
    "\n",
    "- "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Important Inequalities"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Cauchy-Shwarz\n",
    "\n",
    "## Markov\n",
    "\n",
    "## Chebyshev\n",
    "\n",
    "## Jensen"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Background: Formulas\n",
    "\n",
    "## Geometric Series\n",
    "\n",
    "## Exponential Function\n",
    "\n",
    "## Gamma and Beta Integrals\n",
    "\n",
    "## Euler's Approximation for a Harmonic Sum\n",
    "\n",
    "## Stirling's Approximation for Factorials"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}